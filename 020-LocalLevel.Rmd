# The Local Level Model {#localLevel}

## Fitting a Local Level Model

The *local level model* assumes that we observe a time series, $y_{t}$,
and that time series is the sum of another time series, $\mu_{t}$,
and random, corrupting noise, $\epsilon_{t}$.
We would prefer to directly observe $\mu_{t}$,
a *latent* variable,
but cannot due to the noise.

\begin{eqnarray*}
  y_{t} & = & \mu_{t} + \epsilon_{t}, \qquad \epsilon_{t} \sim N(0, \sigma_{\epsilon}^{2}) \\
  \mu_{t} & = & \mu_{t-1} + \xi_{t}, \qquad \xi_{t} \sim N(0, \sigma_{\xi}^{2})
\end{eqnarray*}

In this model, the $\mu_{t}$ follow a random walk,
so this is sometimes called the *random walk with noise* model.
(The `dlm` package uses that name.)

The model has only three parameters.

------------------------- -----------------------------------
 $\sigma_{\epsilon}^{2}$  Variance of the observation errors
 $\sigma_{\xi}^{2}$       Variance of the state transitions
 $\mu_{0}$                Initial level of $\mu$.
------------------------- -----------------------------------

### Problem {-}
You want to fit your time series data to a local level model.

### Solution {-}
The `StructTS` function can estimate the parameters of a local level model
by setting `type="level"`.
(Here, I assume your time series data is $y$.)

```{r, eval=FALSE}
struct <- StructTS(y, type="level")
```

The function returns a list that includes these elements.

----------------- -------------------------------------------------------------------------------
`struct$coef`     2-element vector of estimated variances, labeled `level` and `epsilon`
`struct$model0`   Initial state; in particular `model0$a` is the initial level
`struct$model`    Final model
`struct$code`     Convergence code from optimizer, zero is good, non-zero is bad
----------------- -----------------------------------------------------------------------------

### Example {-}
This example constructs a local level model for the Nile data.
```{r, eval=TRUE}
y <- datasets::Nile

struct <- StructTS(y, type="level")
if (struct$code != 0) stop("optimizer did not converge")

print(struct$coef)

cat("Transitional variance:", struct$coef["level"], "\n",
    "Observational variance:", struct$coef["epsilon"], "\n",
    "Initial level:", struct$model0$a, "\n")
```

### Discussion {-}

### Alt. Solution {-}

The solution, above,
uses the `StructTS` function because that's the easiest way to estimate the model parameters.
Sometimes, however, you might want to use the `dlm` package instead,
even though it's a bit more work.
Why would one do that?
The local level model might be your first step in model building,
leading to more complicate models.
Or you might want to bootstrap your model, which is more easily done using `dlm`.
Or you might want to combine a local level model with another model
using the model "addition" feature of `dlm`.

The `dlm` authors refer to the local level model as
the _random walk with noise_ model:
the underlying level follows a random walk,
and our observation of it is polluted by noise.

Mathematically, the local level models used by the `StructTS` function and the `dlm` package
are the same,
but they use different variable names
and slightly different notational conventions.

\begin{eqnarray*}
  Y_{t} & = & \mu_{t} + v_{t}, \qquad v_{t} \sim N(0, V) \\
  \mu_{t} & = & \mu_{t-1} + w_{t}, \qquad w_{t} \sim N(0, W)
\end{eqnarray*}

Under these conventions,
we observe $Y_{t}$ (not $y_{t}$),
and the variances of the error terms are generalized to be matrices $V$ and $W$.

(*Move to footnote:* Generalizing $V$ and $W$ to matrices will open the door to the multivariate case.)

Following those conventions, the model has these three parameters.

------ ------------------------------------
 `dV`  Variance of the observation errors
 `dW`  Variance of the transition errors
 `m0`  The initial value ($\mu_{0}$)
------ ------------------------------------

The R code begins by defining the `buildModPoly1` function
which can create the needed `dlm` model object from three parameters.

```{r, eval=FALSE}
buildModPoly1 <- function(v) {
  dV <- exp(v[1])
  dW <- exp(v[2])
  m0 <- v[3]
  dlmModPoly(1, dV=dV, dW=dW, m0=m0)
}
```

The R function itself takes one parameter, a 3-element vector,
into which the model parameters are packed.
The first two parameters are log-variance, not variance,
to prevent the optimizer from exploring negative values for variance.

To start, we need some reasonable guesses at the parameters.
They don't need to be perfect, but being in the right ballpark is useful.
```{r, eval=FALSE}
varGuess <- var(diff(y), na.rm=TRUE)
mu0Guess <- as.numeric(y[1])
```

The `dlmMLE` function finds the maximum likelihood estimate of the parameters,
starting with our reasonable guesses and
repeatedly calling our `buildModPoly1` until it converges on the MLE solution.
Always check for convergence.

```{r, eval=FALSE}
parm <- c(log(varGuess), log(varGuess), mu0Guess)
mle <- dlmMLE(y, parm=parm, buildModPoly1)

if (mle$convergence != 0) stop(mle$message)
```

From the MLE parameter estimates, we can build the final model.
```{r, eval=FALSE}
model <- buildModPoly1(mle$par)
```

### Alt. Example {-}

```{r, eval=TRUE}
library(dlm)

y <- datasets::Nile

buildModPoly1 <- function(v) {
  dV <- exp(v[1])
  dW <- exp(v[2])
  m0 <- v[3]
  dlmModPoly(1, dV=dV, dW=dW, m0=m0)
}

varGuess <- var(diff(y), na.rm=TRUE)
mu0Guess <- as.numeric(y[1])

parm <- c(log(varGuess), log(varGuess), mu0Guess)

mle <- dlmMLE(y, parm=parm, buildModPoly1)
if (mle$convergence != 0) stop(mle$message)

model <- buildModPoly1(mle$par)

cat("Observational variance:", model$V, "\n",
    "Transitional variance:", model$W, "\n",
    "Initial level:", model$m0, "\n")
```

### See Also {-}

## Diagnosing a Local Level Model

## Smoothing With a Local Level Model

### Problem {-}

### Solution {-}

### Example {-}

### Discussion {-}

### Alt. Solution {-}

### See Also {-}

## Filtering With a Local Level Model

## Forecasting with a Local Level Model
